import streamlit as st
import pandas as pd
import json
import io
import re
import gspread
from google.oauth2.service_account import Credentials

# -------------------------------------------------------------------------
# [ì›¹í”„ë¡œê·¸ë˜ë° ì „ë¬¸ê°€] 1. í™˜ê²½ ì„¤ì • ë° DB ì—°ê²°
# -------------------------------------------------------------------------
st.set_page_config(layout="wide", page_title="ì‚¬ë°©ë„· ì†”ë£¨ì…˜ v3.0 (Cloud DB)")

# Google Sheets ì—°ê²° í•¨ìˆ˜ (ìºì‹±ì„ í†µí•´ ì†ë„ ìµœì í™”)
@st.cache_resource
def get_db_connection():
    # Streamlit Secretsì—ì„œ ì¸ì¦ ì •ë³´ ë¡œë“œ
    scope = ['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive']
    
    # st.secretsê°€ ìˆëŠ” ê²½ìš°(ë°°í¬/ë¡œì»¬ ì„¤ì •)ì™€ ì—†ëŠ” ê²½ìš° ì˜ˆì™¸ì²˜ë¦¬
    try:
        credentials_info = st.secrets["gcp_service_account"]
        creds = Credentials.from_service_account_info(credentials_info, scopes=scope)
        client = gspread.authorize(creds)
        
        # ì‹œíŠ¸ ì—´ê¸° (Secretsì— ì €ì¥ëœ ì‹œíŠ¸ URL ë˜ëŠ” ID ì‚¬ìš©)
        sheet_url = st.secrets["private_sheet_url"] 
        sheet = client.open_by_url(sheet_url)
        return sheet.sheet1  # ì²« ë²ˆì§¸ ì‹œíŠ¸ ì‚¬ìš©
    except Exception as e:
        st.error(f"DB ì—°ê²° ì‹¤íŒ¨: secrets ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”. ({e})")
        return None

# ë§¤í•‘ ë°ì´í„° ë¡œë“œ (Google Sheets -> Dict)
def load_mappings_from_db(worksheet):
    if worksheet is None: return {}
    try:
        # ëª¨ë“  ë ˆì½”ë“œ ê°€ì ¸ì˜¤ê¸° (Expected columns: 'Vendor', 'MappingData')
        data = worksheet.get_all_records()
        mapping_dict = {}
        for row in data:
            vendor = row.get('Vendor')
            mapping_json = row.get('MappingData')
            if vendor and mapping_json:
                try:
                    mapping_dict[vendor] = json.loads(mapping_json)
                except:
                    continue
        return mapping_dict
    except Exception:
        # ì‹œíŠ¸ê°€ ë¹„ì–´ìˆê±°ë‚˜ ì»¬ëŸ¼ì´ ì—†ëŠ” ì´ˆê¸° ìƒíƒœ ì²˜ë¦¬
        if worksheet.row_count == 0 or not worksheet.get_values():
            worksheet.append_row(['Vendor', 'MappingData']) # í—¤ë” ìƒì„±
        return {}

# ë§¤í•‘ ë°ì´í„° ì €ì¥ (Dict -> Google Sheets Upsert)
def save_mapping_to_db(worksheet, vendor, mapping_data):
    if worksheet is None: return False
    try:
        # ê¸°ì¡´ ë°ì´í„° í™•ì¸
        cell = worksheet.find(vendor)
        json_str = json.dumps(mapping_data, ensure_ascii=False)
        
        if cell:
            # ì´ë¯¸ ì¡´ì¬í•˜ë©´ Update (Vendor ì˜† ì¹¸ì¸ Bì—´ ì—…ë°ì´íŠ¸)
            worksheet.update_cell(cell.row, 2, json_str)
        else:
            # ì—†ìœ¼ë©´ Insert
            worksheet.append_row([vendor, json_str])
        return True
    except Exception as e:
        st.error(f"ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False

# ì •ê·œí™” í•¨ìˆ˜ (ìŠ¤ë§ˆíŠ¸ ë§¤í•‘ìš©)
def normalize_header(header):
    header = re.sub(r'\[.*?\]', '', str(header))
    return re.sub(r'[^ê°€-í£a-zA-Z0-9]', '', header).lower()

# -------------------------------------------------------------------------
# [ì›¹í”„ë¡œê·¸ë˜ë° ì „ë¬¸ê°€] 2. ë©”ì¸ ë¡œì§ ì‹œì‘
# -------------------------------------------------------------------------
st.title("â˜ï¸ ì‚¬ë°©ë„· ëŒ€ëŸ‰ë“±ë¡ ì†”ë£¨ì…˜ v3.0 (Google DB ì—°ë™)")
st.markdown("""
> **System Info**: ë§¤í•‘ ê·œì¹™ì´ **Google Sheets**ì— ì•ˆì „í•˜ê²Œ ì €ì¥ë©ë‹ˆë‹¤.
> ë™ë£Œë“¤ê³¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ë§¤í•‘ ì •ë³´ë¥¼ ê³µìœ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
""")

# DB ì—°ê²° ì‹œë„
worksheet = get_db_connection()
if not worksheet:
    st.stop() # DB ì—°ê²° ì•ˆë˜ë©´ ì¤‘ë‹¨

col1, col2 = st.columns([1, 2])

with col1:
    st.subheader("1. íŒŒì¼ ì—…ë¡œë“œ")
    file_01 = st.file_uploader("01. ì–‘ì‹ íŒŒì¼ (Target)", type=['csv', 'xlsx'])
    file_02 = st.file_uploader("02. ë°ì´í„° íŒŒì¼ (Source)", type=['csv', 'xlsx'])

if file_01 and file_02:
    try:
        # íŒŒì¼ ì½ê¸°
        if file_01.name.endswith('.csv'): df_target = pd.read_csv(file_01, encoding='cp949')
        else: df_target = pd.read_excel(file_01)
            
        if file_02.name.endswith('.csv'): df_source = pd.read_csv(file_02, encoding='cp949')
        else: df_source = pd.read_excel(file_02)

        target_columns = df_target.columns.tolist()
        source_columns = df_source.columns.tolist()

        with col2:
            st.subheader("2. ìŠ¤ë§ˆíŠ¸ ì»¬ëŸ¼ ë§¤í•‘ (DB Synced)")
            supplier_name = st.text_input("ê±°ë˜ì²˜ëª… (ì €ì¥ Key)", placeholder="ì˜ˆ: ë‚˜ì´í‚¤")
            
            # DBì—ì„œ ë§¤í•‘ ì •ë³´ ë¡œë“œ
            mappings_db = load_mappings_from_db(worksheet)
            saved_mapping = mappings_db.get(supplier_name, {})
            
            if supplier_name and supplier_name in mappings_db:
                st.success(f"ğŸ“‚ Cloud DB: '{supplier_name}' ë§¤í•‘ ë¶ˆëŸ¬ì˜¤ê¸° ì„±ê³µ!")

            st.markdown("---")
            
            user_selections = {}
            with st.container(height=600):
                for target_col in target_columns:
                    c1, c2, c3 = st.columns([2, 2, 0.5])
                    with c1:
                        display_text = target_col.replace("\n", " ")
                        if "[í•„ìˆ˜]" in display_text:
                            st.markdown(f"**ğŸ”´ {display_text}**")
                        else:
                            st.text(display_text)
                    
                    default_idx = 0
                    match_type = ""
                    
                    # 1. DB ì €ì¥ê°’ í™•ì¸
                    if saved_mapping.get(target_col) in source_columns:
                        default_idx = source_columns.index(saved_mapping[target_col]) + 1
                        match_type = "ğŸ’¾"
                    # 2. ìŠ¤ë§ˆíŠ¸ ë§¤í•‘
                    else:
                        target_clean = normalize_header(target_col)
                        for idx, src_col in enumerate(source_columns):
                            src_clean = normalize_header(src_col)
                            if target_clean and (target_clean == src_clean or target_clean in src_clean):
                                default_idx = idx + 1
                                match_type = "ğŸ¤–"
                                break
                    
                    with c2:
                        selected = st.selectbox(
                            f"Select {target_col}", ["(ë§¤í•‘ ì•ˆí•¨)"] + source_columns, 
                            index=default_idx, key=f"map_{target_col}", label_visibility="collapsed"
                        )
                        if selected != "(ë§¤í•‘ ì•ˆí•¨)":
                            user_selections[target_col] = selected
                    with c3:
                        if match_type: st.text(match_type)

            if st.button("í˜„ì¬ ë§¤í•‘ Cloud DBì— ì €ì¥"):
                if not supplier_name:
                    st.error("ê±°ë˜ì²˜ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                else:
                    with st.spinner("Google Sheetsì— ì €ì¥ ì¤‘..."):
                        if save_mapping_to_db(worksheet, supplier_name, user_selections):
                            st.toast(f"âœ… '{supplier_name}' ì €ì¥ ì™„ë£Œ!", icon="â˜ï¸")
                            st.cache_resource.clear() # ìºì‹œ ê°±ì‹  (ì„ íƒì‚¬í•­)
                        else:
                            st.error("ì €ì¥ ì‹¤íŒ¨")

    # ë³€í™˜ ë° ë‹¤ìš´ë¡œë“œ ë¡œì§ (ì´ì „ê³¼ ë™ì¼í•˜ì—¬ í•µì‹¬ë§Œ ìœ ì§€)
    st.divider()
    if st.button("ë°ì´í„° ë³€í™˜ ë° ê²€ì¦ ì‹¤í–‰"):
        with st.spinner('ì²˜ë¦¬ ì¤‘...'):
            result_df = pd.DataFrame(columns=target_columns)
            for t_col, s_col in user_selections.items():
                result_df[t_col] = df_source[s_col]
            result_df = result_df.fillna("")
            
            # Validation
            errs = []
            for col in target_columns:
                if "[í•„ìˆ˜]" in col:
                    empty_cnt = (result_df[col] == "").sum() + result_df[col].isna().sum()
                    if empty_cnt > 0: errs.append(f"âš ï¸ **{col}**: {empty_cnt}ê±´ ëˆ„ë½")
            
            if errs:
                st.error("í•„ìˆ˜ê°’ ëˆ„ë½ ë°œê²¬!")
                for e in errs: st.write(e)
            else:
                st.success("ë¬´ê²°ì„± ê²€ì¦ í†µê³¼!")

            # Excel Output
            output = io.BytesIO()
            with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                result_df.to_excel(writer, index=False)
                ws = writer.sheets['Sheet1']
                for i, col in enumerate(result_df.columns):
                    ws.set_column(i, i, 20) # ê°„ëµí™”ëœ ë„ˆë¹„ ì¡°ì •
            output.seek(0)
            
            st.download_button("ğŸ“¥ ê²°ê³¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ", output, f"{supplier_name}_ì™„ë£Œ.xlsx")

except Exception as e:
    st.error(f"ì˜¤ë¥˜: {e}")